---
title: "Against Rationalism"
date: 2023-03-04T08:55:54-08:00
summary: Intro for some later-on thoughts about cognition and the evolution of same.
tags:
    - against-rationalism
    - metablogging
---

I want to use this tag later, and these are fuzzy terms outside of academia, so
some explanations and definitions seem appropriate.

## Rationalism and Empiricism, Plato and Aristotle

**Rationalism:** The conviction that it's possible to asymptotically[^10]
approach a model of reality which is both "correct" and unitary.

**Empiricism:** The conviction that no unitary model of reality can ever
approach "correctness" more closely than a sequence or collection of disjoint
models.[^20]

Where "correctness" is basically the ability to explain all the available
observations, *and* reliably, accurately predict future observations.

There are a lot of other angles on this debate. In Western philosophical
tradition it goes back to Plato and his ideal forms vs Aristotle and his messy
reality.  Not to mention various "modern" and "post modern" questions, like
whether models always precede observations, how exactly models constrain
observations, and so on.

It's safe to stop here if you just wanted to know what the tag was about.

## "Bounded" Rationalism

Applied to the (messy!) landscape of real-world cognitive strategies,
rationalism encourages devoting a lot of resources to refining one, or perhaps a
few, high-value models, and optimizing for predictive value.  This cognitive
strategy is a lot cheaper, but vulnerable to occasional catastrophic "blind
spot" errors.

Empiricism, which tends to encourages "parallel" models and fewer "discarded"
observations, is more computationally expensive in general but seems to be
somewhat less likely to get you killed.

Nowadays most of us like to *pretend* that we – the "selves" that we identify
with – operate mostly in an empiricist mode.  Or at least an only
weakly-rationalist one.[^25]  But the "self" part of our hardware tends very
strongly toward pure rationalism, for perfectly good reasons, and most of us
struggle with that.  IMO that struggle is worthwhile.  Hence, "against
rationalism."

## Society of Mind

> We do, doodly do, doodly do, doodly do.  What we must, muddily must, muddily
  must, muddily must.  Muddily do, muddily do, muddily do.  Until we
  bust, bodily bust, bodily bust, bodily bust.
  — Kurt Vonnegut

IMO it's helpful to think of human cognition as a bunch of kludgey empiricist
hardware delivering a strongly Rationalist "user experience." Which is to say
that *very* loosely speaking, our hardware consists of a variety of imperative
process-control models which run in parallel, competing for control of an
operational decision-making apparatus, plus a semi-detached fundamentally
Platonic "narrative" or "symbolic" layer which "explains" those decisions
(mostly after the fact) and occasionally gets to use that narrative to choose
some high level parameter or make some decision that applies to the system as a
whole.

Our software, so to speak, is mostly acquired as the hardware matures, but it's
remarkably flexible in that respect and can definitely be very daramatically
"refactored" all the way into late adulthood.

This cognitive strategy has been insanely successful. And even if it suddenly
*stopped* working well for us, we'd be kind of stuck with it, because there's
only so flexible our neurological hardware can be.

## Mind of Society

It's not controversial to say that our cognitive hardware has been at a heavily
"domesticated" and "prosocial" equilibrium for quite a long time[^30], and that
has allowed us to explore a vast state space of different kinds of
"proto-eusocial" norms and social arrangements.

But I also suspect that ever since we made the transition from solar/muscle to
fossil/nuclear, and then almost immediately unlocked the "nitrogen-fixer"
achievement, the reproductive benefit of "proto-eusocial" behavior modes have
suddenly become so much greater than what our prosocial brains are used to that
it's destabilized the prosocial equilibrium.  And now we're *collectively*
struggling to reach a new one. I wonder if that idea should have its own tag.

<!-- end content -->

[^10]: Thanks to Ed Lorenz (Peace Be Upon Him), and many others, we now realize
    that we can't actually run a "truly correct" model in practice, even if it
    could exist in principle.  But OTOH we haven't proven that such a model
    can't be approached, either in principle or in practice.

[^20]: Yeah, yeah.  These are *my* definitions of rationlaism and empiricism,
    and I mostly consider myself an empiricist and I'm heavily influcenced by
    the George Box quote. If you don't like it go read a *real* philosopher.

[^25]: I mean, you ask pretty much any modern human about this and they're
    likely to scoff at the Platonic view that reality involves some "ideal
    table" which all actually existing tables reflect.  But our *actual*
    cognitive stack is all about heavily filtering and then reifying raw
    measurements.  We just don't think of them as heavily filtered, because
    denormalizing/particularizing them all the time would be so cognitively
    expensive that we would never get anything else done, and we don't think of
    them as reified because that would defeat their purpose.

[^30]: Let's say no less than few dozens of kiloyears ago, in order to be
    conservative. I don't know enough about hominin history to have strong
    opinions about where the right place to start counting would be, and
    wouldn't object if somebody told me going all the way back a couple of
    million would be better.
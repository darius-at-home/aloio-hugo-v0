---
title: "Much Less in Charge Than It Might Seem"
date: 2023-03-05T12:14:08-08:00
tags: ["against-rationalism", "AI-pocalypse", "ChatGPT"]
---

## LOL

Not even an hour after publishing [this]({{< ref "posts/against-rationalism">}})...

> IMO it's helpful to think of human cognition as a bunch of kludgey empiricist
> hardware delivering a strongly Rationalist "user experience." Which is to say
> that *very* loosely speaking, our hardware consists of a variety of imperative
> process-control models which run in parallel, competing for control of an
> operational decision-making apparatus, plus a semi-detached fundamentally
> Platonic "narrative" or "symbolic" layer which "explains" those decisions
> (mostly after the fact) and occasionally gets to use that narrative to choose
> some high level parameter or make some decision that applies to the system as
> a whole.

...I visited fosstodon while having lunch, and ran across this
[masterpiece][geepaw-hill] of understatement ðŸ¤£:

> I don't have any delicate way to express his thesis. He does, he
> develops it slowly and carefully. But that ain't me.
>
> My rude version: You are not an abstract theoretical computation
> device. You are an animal. You are an evolved animal. Your mind, your
> will, your spirit, is very very very much less in charge than it might
> seem to you.

-- [GeePawHill][geepaw-hill]

## And As Long As I'm Back Here

That [Emily Bender article][emily-bender] people have been raving about
is every bit as good as they say.

I also strongly recommend this [Erik Hoel post][erik-hoel], which does a great
job of explaining the "dumbish AIs are plenty dangerous enough" synthesis
between the "AIs are not smart enough to be dangerous yet" and the "AGI fast
takeoff scenarios are nonsensical" perspectives.

I have some quibbles with it, but nothing worth talking about when I'm supposed
to be packing for a trip.  And I dearly wish more people understood this part in
particular:

> So to say that a massive billion-parameter neural network is â€œmerelyâ€ trained
> to autocomplete text is true. . . but that has absolutely no bearing on
> whether itâ€™s dangerous, or what itâ€™s capable of. Otherwise, we could say that
> humans arenâ€™t dangerous because we are merely â€œglorified gene spreadersâ€ or
> that brains arenâ€™t impressive because they are just â€œglorified surprise
> minimizers.â€ The exact same reasoning is true for these AIs that demonstrate
> general intelligence off of autocompleting text.

Not only about the "Fast AIs" that are making headlines, but also about various
kinds of "Slow AIs" that we seem to have accepted as our collective overlords.


[geepaw-hill]: https://fosstodon.org/@GeePawHill@mastodon.social/109969351414578622
[emily-bender]: https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html
[erik-hoel]: (https://erikhoel.substack.com/p/how-to-navigate-the-ai-apocalypse)